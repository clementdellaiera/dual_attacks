\documentclass{article}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xcolor}
%\usepackage{nicematrix}

\setlength\parindent{0pt} %no indentation for paragraph

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}[theorem] 
\newtheorem{lemma}{Lemma}

\title{Review of the dual attack on euclidean lattices}
\author{Clément Dell'Aiera - Pierre-Alain Fouque - Tuong-Huy Nguyen}

\begin{document}
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%
\maketitle
Critics of the dual attack have focused their arguments on the following points :
\begin{itemize}
\item[$\bullet$] The independence of the summands in the distiguisher.
\item[$\bullet$] The distribution of the output of a sieve.
\item[$\bullet$] The contradictory regime that follows from numerical experiment. The attack could not work for some specific choices of parameters, choices that were determined experimentally.
\end{itemize}

\subsection{Independance}

The independance heurisic refers to the following problem. Let $W\subset  \Lambda^\vee$ be a family of vectors and $t\in \mathbb R^n$, all of which are sampled from probability distributions. Even if we suppose that all vectors in $W$ are mututally independant, the random variables 
\[\cos (\langle w ,t \rangle) \text{ for }w\in W\]
are not. 

This should in principle invalidate the use of Hoeffding inequality which requires the summands to be independant. But the bound obtained does not depend on the value of $t$, which by a simple conditionning allows us to still obtain the same bound. Indeed, $\cos (\langle w ,t \rangle)$ are independant conditionally to $t$, i.e. for every family of measurable subsets $\{A_w\}_{w\in W}$ of $\mathbb R$, we have
\[ \mathbb P(\cap_{w\in W} \cos (\langle w ,t \rangle) \in A_w | t) =\prod_{w\in W} \mathbb P(\cos (\langle w ,t \rangle) \in A_w | t) .\] 
In \cite{PoulyShen}, the use of Hoeffding inequality ensures that
\[\mathbb P(|g_w(t)-f(t)| > \varepsilon |t) \leq Ce^{-c\varepsilon^2}.\]
Then 
\[\begin{split}
\mathbb P(|g_w(t)-f(t)| > \varepsilon ) & =\int \mathbb P(|g_w(t)-f(t)| > \varepsilon |t = t')\mathbb P_t(dt') \\
		& \leq Ce^{-c\varepsilon^2}\\
\end{split}\]
Thus, we see that $g_w(t)$ concentrated around its mean value $f(t)$, even in the independance heuristic.

\subsection{Output of a sieve}

The distribution of vectors in $W$ also influence the validity of the distinguisher. Indeed, the analysis carried in \cite{pouly2023provable} relies on the assumption that the element of $W$ are sampled independantly from $D_{\Lambda^\vee ,s^{-1}}$. In that case, the distinguisher can be determined via an application of the Poisson summation formula. We have that 
\[f(t) = \mathbb E[g_W(t)|t ] = \frac{\rho_s(\Lambda + t)}{\rho_s(\Lambda)}.\] 
Using inequalities from the ,\\

details about isotropy \\

In other works (\cite{carrier2024reduction}, \cite{ducas2023accurate}), the output of a sieve is modelled as a uniform distribution on either a euclidean ball or a thick sphere. In these cases, the computation of the distinguisher relies on classical harmonic analysis of radial function, i.e. decomposition of the characteristic function against spherical harmonics, given by Bessel functions. See for instance \cite{}}\\

Let us describe more precisely the previous paragraph. Let $B^{(d)}(r)$ be the euclidean ball $\{x\in\mathbb R^d \ : \  \|x\|_2\leq r\}$ and $S^{(d)}(r,\delta)$ be the thick sphere 
\[ B^{(d)}(r+\delta) \backslash B^{(d)}(r-\delta).\] 
Then if $W\sim\mathcal U(B^{(d)}(r))$,
\[\begin{split}
f(t) & = \mathbb E[e^{i\langle W, t\rangle}] \\
	& = \int_{\mathbb R^n} \chi_{B^{(d)}(r)}(x) e^{i\langle x, t\rangle}dx . \\
\end{split}\]
In the case where $\tilde W\sim\mathcal U(S^{(d)}(r,\delta))$, 
\[\begin{split}
\tilde f(t)  & = \mathbb E[e^{i\langle \tilde W, t\rangle}]\\
	& =  \int_{\mathbb R^n} \chi_{B^{(d)}(r+\delta)}(x) e^{i\langle x, t\rangle}dx - \int_{\mathbb R^n} \chi_{B^{(d)}(r-\delta)}(x) e^{i\langle x, t\rangle}dx. \\
\end{split}\]

\subsubsection{Gaussian sampling of short dual vectors}
By theorem \ref{BochnerLattices}, the function 
\[f(t) = \frac{\rho_s(t+\Lambda)}{\rho_s(\Lambda)}\]
is in the image of the Fourier transform. Using the Poisson formula applied to the discrete gaussian function, we get 
%is such a kernel, and 
%We can actually determine ita analytically using  the Fourier transform of the gaussian function and the Poisson formula : $f = \mathcal F(\eta) $ for 
%\[\eta(w) = \frac{\rho_{\frac{1}{s}} (\|w\|^2)}{\rho_s(\Lambda) \det(\Lambda)} \quad\forall w\in \Lambda^\vee.\] 
\[\begin{split} 
f(t) & = \frac{ \rho_s (\Lambda + t)}{\rho_s (\Lambda )} \\ 
	& = \frac{ ( \rho_{s^{-1}} e^{2i\pi \langle \bullet , t\rangle }) (\Lambda^\vee) }{ \rho_{s^{-1}}(\Lambda^\vee)} \\
	& = \rho_{s^{-1}}(\Lambda^\vee)^{-1}\sum_{w\in \Lambda^\vee} \rho_{s^{-1}}(w) \cos (2\pi \langle w,t\rangle ) .
\end{split}\]
This ensures that if $W$ is a random variable following $D_{\Lambda^\vee, s^{-1}}$, then 
\[f(t) = \mathbb E[\cos (2\pi \langle W , t \rangle ) ] \quad \forall t\in \mathbb R^n.\] 

Let $W_1,\ldots , W_N$ be i.i.d random variables with law $D_{\Lambda^\vee, s^{-1}}$. The random variables $\cos (2\pi \langle W , t \rangle ) $ are bounded. 
Let us denote $\frac{1}{N}\sum_{k=1}^N \cos (2\pi \langle W_k , t \rangle )$ by $g_N(t)$. Then , by Chebyshev inequality,
\[\mathbb P( |g_N(t) - f(t) |\geq \varepsilon ) \leq  2 \exp( - \frac{2\varepsilon^2}{4N}) \quad \forall \varepsilon >0.\]

The provable regime of Pouly-Shen follows from the properties of $\frac{ \rho_s (\Lambda + t)}{\rho_s (\Lambda )}$ as a distinguisher, which highly depends on $s$. This analysis breaks down if we consider $W_1,\ldots , W_N$ sampled from a sieve (and not sampled as independent draws of $D_{\Lambda,s^{-1}}$). 

However, most papers (including \cite{ducas2023accurate}) assume that the output of a sieve is a sample of independent variables distributed as a uniform random variable on a Euclidean ball. In that case, the distinguisher can be computed as $f(t) = \mathbb E[e^{2i\pi\langle W , t \rangle} )]$ for $W\sim \mathcal U(B_n(r_{\text{sat}} \mathfrak{gh}_n))$ and approximated with a sample of size $N = \frac{1}{2}f_{\text{sat}}r_{\text{sat}} $ (see heuristic 2 of \cite{ducas2023accurate}, page 7). It remains to study if the behavious of $f(t)$ with respect to the distance. One reason for optimism is that gaussians in high dimensions are concentrated on spheres, thus I would expect the behaviours to be close. 

\textcolor{blue}{The computation of the Fourier transform of the characteristic function of a ball is a classical result. In \cite{ducas2023accurate} (see lemma 2 page 9) and \cite{carrier2024reduction} (see proposition 7), authors actually use it  }   

We can summarize the discussion above by the following.

\begin{corollary}
Let $W_1,\ldots , W_N$ be a independent identically distributed random vector distributed as $D_{\Lambda^\vee , s^{-1}}$ and 
\[g_N(t) = \sum_{k=1}^N\cos(2\pi \langle W_k,t\rangle )\quad\forall t\in\mathbb R^n.\] 
Then 
\[\mathbb P( |g_N(t) - \frac{\rho_s(t+\Lambda)}{\rho_s(\Lambda)}) |\geq \varepsilon ) \leq  2 \exp( - \frac{2\varepsilon^2}{4N}) \quad \forall \varepsilon >0.\]
\end{corollary}

In order to relate this result to solving CVP, we can use the following inequality (see \cite{banaszczyk1993new}) 
\[ e^{-s\pi d(t,\Lambda)^2} \leq \frac{\rho_s(t+\Lambda)}{\rho_s(\Lambda)}\leq 1 \]
\begin{proof}(from \cite{stephens2017gaussian}, lemma 1.3.10)
Up to translating by element of $\Lambda$, we can suppose that $t$ is in the Voronoi fundamental domain, i.e. $d(t,\Lambda) = \|t\|$, and thus $\rho_s(t)= e^{-s\pi d(t,\Lambda)^2}$. Then 
\[\begin{split}
\rho_s(\Lambda - t ) &= \frac{1}{2}\sum_{v\in \Lambda} ( \rho_s(v-t) + \rho_s(-v-t)) \\
	& = \rho_s(t) \sum_{v\in \Lambda}\rho_s(v) \text{cosh}(2s\pi\langle v,t\rangle)\\
	& \geq  \rho_s(t)\rho_s(\Lambda) \\ 
\end{split}\]
\end{proof}

\subsubsection{Sampling of short dual vectors via sieving}

For $B\in GL(d,\mathbb R)$, let $b_1$ be $B$'s first column and let us denote $\frac{\|b_1\|}{\text{det}(B)^{1/d}}$ as $\delta_B$.\\

On input a basis $B$ of a lattice $\Lambda$, BKZ$_\beta$ with a sieving oracle as SVP oracle outputs vectors that can be modeled as one of the following :
\begin{itemize}
\item[$\bullet$] $N = \frac{1}{2}f_{sat}r_{sat}^n$ independant uniform random variables on a ball of radius $r_{sat} \mathfrak{gh}_n$, where $r_{sat}\geq 1$ is the saturation radius, and $f_{sat}\in (0,1]$ is the saturation ratio (see Heuristic 2 of \cite{ducas2023accurate}).
\item[$\bullet$] independant uniform random variables on $\Lambda^\vee \cap \{t\in \mathbb R^d : R-\varepsilon\leq \|x\| \leq R+\varepsilon\}$ (see section of \cite{carrier2024reduction}). 
\item[$\bullet$] independant (continuous) normal variables $\mathcal N(0,R I_d)$ (assumption 21 and 23 of \cite{espitau2020dual}). 
\end{itemize}
where $R = \delta_B^d det(\Lambda)^{1/d} / \sqrt{d}$. \\

As models, all these heuristics are approximately the same. Indeed, in high dimensions, gaussian vectors are concentrated on a sphere (the same holds for uniform vectors on a euclidean ball). This comes from the fact that coordinates are sub-gaussian, thus their norms are sub-exponential, and these families of probabilities satisfy an inequality of the type 
\[\mathbb P(| \|X\|_2 - \sigma \sqrt{d} |> t  ) \leq 2\exp(-ct^2)\quad \forall t>0\]
for some constant $c>0$. See chapter 3 of \cite{vershynin2018high} (section 3.4). \\
   
\textcolor{blue}{A remark : it is surprising that the result of a sieve should be isotropic. If a lattice is sampled at random, there is no prefered direction and the general shape of a reduced basis should be isotropic (this is an argument I have read somewhere)\footnote{Shouldn't this contradict the Geometric Series Assumption.}. However, conditionnal to the choice of a lattice, there should be some distortion. I would expect that the distribution $\mathcal N(0,\Sigma)$, where $\Sigma = B^*B$ for a reduced basis, would be relevant since it captures the shape of the lattice (the unit ball is sent to the ellipsoid with axes corresponding to the vectors of the basis). }

The output of a sieve is modelled by a variety of distributions, which all have in common that they are sub-gaussian and thus are concentrated on a sphere. It is not crucial to know the exact distribution of the output as long as one can efficiently bound the constant in the inequality
\[\mathbb P(| \ \|\xi\| - r\sqrt{d} \ | \geq t) \leq C\exp(-ct^2).\]
Indeed, this allows to derive an success probability for the attack. 

\textcolor{blue}{It might be doable to model the sieve as a random process, such as a Markov chains, that stays sub-gaussian. The discussion above then gives a way to freee oneself from the choice of a particular distribution as the output as the sieve, as long as it is sub-gaussian.}

Déterminer $C,c> 0$ tels que:
\begin{corollary}
Let $P$ a probability distribution on $\Lambda^\vee$ that is sub-exponential. Let $W_1,\ldots , W_N$ be a independent identically distributed random vector sampled via $P$ and 
\[g_N(t) = \sum_{k=1}^N\cos(2\pi \langle W_k,t\rangle )\quad\forall t\in\mathbb R^n.\] 
Then 
\[\mathbb P( |g_N(t) - \frac{\rho_s(t+\Lambda)}{\rho_s(\Lambda)}) |\geq \varepsilon ) \leq  C \exp( - c\varepsilon^2) \quad \forall \varepsilon >0.\]
\end{corollary}
en montrant que $\mathbb Eg_N(t) $ devrait être proche de $\frac{\rho_s(t+\Lambda)}{\rho_s(\Lambda)})$ par approximation gaussienne (obtenue par concentration de la norme).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relative versions of computational problems}%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $G$ be a locally compact abelian group endowed with a metric $d : G\times G \rightarrow \mathbb R$, $H$ a finitely generated subgroup and $\mu$ a probability measure on $G/H$, $\eta$ a probability measure on $G$. Define the following problem
$$\mathcal P_{\text{search}} (G,\mu) : \text{Given } (H,x) \text{ s.t. }x+H \sim \mu , \text{ find argmin}_{a\in H} d(x,a).$$
$$\mathcal P_{\text{decision}}(G,\eta) : \text{Given } (H,t) \text{ where } t\in G, \text{ decide if } t + H \sim \mathcal U(G/H) \text{ vs } t\sim D$$
In particular instances, this problem specializes to well studied problems. The generalization is motivated to highlight some subtle points : it can happen that one has to deal with codes while starting with a problem related to lattices. For example, this phenomenon arises in LWE because the quotient of the LWE lattice $\Lambda_q(A)$ by $q\mathbb Z^n$ is not a lattice but a finite group. 
\[\begin{array}{|c|c|c| c | c|} 
\hline
G             & H                          & d     &  \mu              & \mathcal P (G,H,\mu)\\
\hline
\mathbb R^n   & \Lambda                    & \ell^2 & \chi_e            & \text{CVP}     \\
\mathbb F_q^n & \mathcal C                 & d_H    & \text{uniform on fixed weight}    & \text{Decoding}\\
\mathbb Z^{\text{nrow}(A)}  & \Lambda_q(A) & \ell^2 &  A \chi_s +\chi_e & \text{LWE}     \\
\hline
\end{array}\]

Our work focuses on breaking $BDD(\Lambda)$ into a series of problems with the hope of decreasing the complexity :
\begin{itemize}
\item[$\bullet$] find $\Lambda_0$ such that $BDD(\Lambda_0)$ has quasi-polynomial complexity\footnote{Or just at least a better complexity than expected $BDD$ complexity.}.
\item[$\bullet$] apply the dual attack to reduce $BDD(\Lambda)$ to $BDD(\Lambda_0)$. 
%\item[$\bullet$] for $G = \Lambda/\Lambda_0$, $BDD(\Lambda)$, find $b\in B$ such that  is equivalent to 
\end{itemize} 

We also provide a rigorous statistical model for the attack. For the distinguishing step, we establish an exact deviation bound for the score which does not suppose independance on the terms of the sum. We explicitely link the maximization of the score function to the optimization of the p-value of the tests. The end of the work is devoted to a discussion of the parameters for which the attack is efficient, and comparison with previous work. 

Our result allows a modification of the attack as described in \cite{pouly2023provable}. As we don't need the independance of the summands in the distinguisher, we can use a sieve to generate our sample of short vectors $W$ in $\Lambda^\vee$. This is more efficient than using independant calls to a gaussian sampler iteratively. Moreover, it is not clear that the results in \cite{pouly2023provable} apply even if $W$ is sampled with $|W|$ calls to a sampler, since the different terms are not independant once the randomness of the target is taken into account\footnote{if $w,w'$ are independant and $t\sim D_\Lambda$, $\langle w , t \rangle $ and $\langle w' , t \rangle $ are not necesserily independant.}.   
 
The distinguishing step depends on a sublattice $\Lambda_0 < \Lambda$. One builds a finite set of short vectors $W\subset \Lambda_0^\vee$ and define the distinguisher
$$f_W(t) = \frac{1}{|W|} \sum_{w\in W} \cos (2\pi \langle w, t\rangle ).$$ 
This function is $\Lambda_0$-periodic and thus 
$$ t_0^* = \text{argmax}_{t\in V} f_W(t) = \text{argmax}_{t\in V/\Lambda_0} f_W(t+ \Lambda_0) $$
satisfies $t - t_0^*$ follows a BDD-distribution on $\Lambda_0$.

In the setting of LWE lattices, let us write $A  = [A_{dual} | A_{guess} ]$. With the notations as above, 
$$\Lambda_0 = \Lambda_{q}(A_{dual}) < \Lambda_q(A).$$ 
If the columns of $A$ are independant, we have that 
$$\Lambda_{q}(A) / \Lambda_{q}(A_{dual}) \cong \Lambda_{q}(A_{guess})$$ 
and when the attack is succesful, i.e. $s_{guess} = s_{guess}^*$, we get $t-As_{guess}^* = A_{dual}s_{dual} + e$.

In the setting where $\Lambda / \Lambda_0 = G$ is a finite abelian group (as in \cite{ducas2023does}), we get the problem $\mathcal P(G,\mu)$. In \cite{ducas2023does}, the optimisation of $f_W$ is done first with computing its Fourier transform, which for particular case of groups such as $(\mathbb Z / 2 \mathbb Z)^n$ can be done very efficiently. 

\subsection{Concentration inequalities for lipschitz functions of discrete gaussians}
In order to be able to apply the exact bounds for a LWE distinguisher, we prove concentration inequalities valid for discrete gaussians. 

\begin{lemma}
Let $X$ be a real random variable and $\varphi : \mathbb R \rightarrow \mathbb R$ be a differentiable function such that $t\mapsto \varphi'(t)\mathbb P(X>t)$ is integrable. The following formula holds
$$\mathbb E [\varphi(X)] = \varphi(a) + \int_{a}^{+\infty} \varphi'(t)\mathbb P(X > t) dt \quad \forall a \in \mathbb R.$$
If $\lim_{t\rightarrow -\infty}\varphi(t) =0$, the following also holds
$$\mathbb E [\varphi(X)] = \int_{-\infty}^{+\infty} \varphi'(t)\mathbb P(X > t) dt.$$
\end{lemma}

\begin{proof}
Applying the fundamental theorem of calculus,
$$\varphi(x)-\varphi(a) = \int_a^x\varphi'(t)dt$$
Evaluating the expectation and Fubini interversion theorem concludes the first part.
For the second part, we let $a$ tend to $-\infty$ to get :
$$\varphi(X) = \int_{-\infty}^X\varphi'(t)dt = \int_{-\infty}^{+\infty} \varphi'(t) 1_{\{X > t\}} dt.$$
and concludes in the same manner.
\end{proof}

We call a real random variable $X$ sub-gaussian if there exist constants $C , a>0$ such that 
$$\mathbb P( X > t ) \leq Ce^{-at^2} \quad \forall t >0.$$ 
If we want to keep track of the constants involved, we will call such a variable a $(C,a)$-sub-gaussian random variable.

\begin{theorem}
Let $(M,d)$ be a metric space, and $\xi$ a random variable with values in $M$, such that for every (or equivalently for one) point $m\in M$, the random variable $d(\xi, m)$ is $(C,a)$-sub-gaussian. Let $f : X\rightarrow \mathbb R$ be a lipschitz function with lipschitz constant bounded by $L>0$. Then  
$$\mathbb P(|f(\xi)  - \mathbb E[f(\xi)]| > t) \leq   \frac{C^2a^3}{\pi L^2} \cdot t^2 e^{-\frac{ L^2}{8a}t^2} .$$
\end{theorem}

\begin{proof}
Let $\tilde\xi$ an independant copy of $\xi$, $m\in M$ and $\lambda>0$. We have 
\[\begin{split}
\mathbb P(|f(\xi)  - \mathbb E[f(\xi)]| > t) & \leq e^{-\lambda t} \mathbb E[e^{\lambda |f(\xi)  - \mathbb E[f(\xi)]| } ] \\ 
		& \leq  e^{-\lambda t} \mathbb E[\exp({\lambda \mathbb E[|f(\xi)-f(\tilde \xi)| \ | \ \xi] })] \\
		& \leq  e^{-\lambda t} \mathbb E[e^{\lambda |f(\xi)-f(\tilde \xi)| }] \\
		& \leq  e^{-\lambda t} \mathbb E[e^{\lambda Ld(\xi , \tilde \xi) }] \\
		& \leq e^{-\lambda t} \mathbb E[e^{\lambda Ld(\xi , m) }]^2 \\
\end{split}
\]
The preceeding lemma applied to $\varphi(u) = e^{L\lambda u}$ and $X=d(\xi,m)$ ensures that
\[\begin{split}
\mathbb E [e^{\lambda L d(\xi , m)} ] & = \lambda L \int_{-\infty}^{+\infty} e^{\lambda L u} \mathbb P(d(\xi,m) > u) du \\
	& \leq C\lambda L \int_{-\infty}^{+\infty} e^{\lambda L u-au^2} du \\
	& \leq C\lambda L e^{a\frac{\lambda^2L^2}{4a^2}}\int_{-\infty}^{+\infty} e^{-a(u-\frac{\lambda L}{2a} )^2} du \\
	& \leq C\lambda L \sqrt{\frac{a}{\pi}} e^{\frac{\lambda^2L^2}{4a}} .\\
\end{split}\]
Replacing in the last inequality, we get
\[\begin{split}
\mathbb P(|f(\xi)  - \mathbb E[f(\xi)]| > t) & \leq C^2 L^2 \frac{a}{\pi} \cdot \lambda^2 e^{\frac{ L^2}{2a}\lambda^2 -\lambda t} \\ 
\end{split}
\]
Setting $\lambda = \frac{at}{L^2} $, we get the result. I did not dare minimizing in $\lambda$. 
\end{proof}

Suppose now that there exist constants $C , a , t_0>0$ such that 
$$\mathbb P( X > t ) \leq Ce^{-at^2} \quad \forall t >t_0.$$
The same method as in the previous result yields 
$$\mathbb E [e^{\lambda L d(\xi , m)} ] \leq e^{\lambda L t_0}  + C\lambda L \sqrt{\frac{a}{\pi}} e^{\frac{\lambda^2L^2}{4a}} $$
hence 
$$\mathbb P(|f(\xi)  - \mathbb E[f(\xi)]| > t) \leq e^{-\lambda t} \left(e^{\lambda L t_0}  + C\lambda L \sqrt{\frac{a}{\pi}} e^{\frac{\lambda^2L^2}{4a}}\right)^2 $$
If $\lambda = \frac{at}{L^2} $, we get
\[\begin{split}
\mathbb P(|f(\xi)  - \mathbb E[f(\xi)]| > t) & \leq e^{-\lambda t} \left(e^{\lambda L t_0}  + C\lambda L \sqrt{\frac{a}{\pi}} e^{\frac{\lambda^2L^2}{4a}}\right)^2 \\
					& \leq \left( e^{at_0^2}e^{-a(\frac{t}{L} - t_0)^2} + \frac{C^2a^3}{\pi L^2} \cdot t^2 e^{-\frac{ L^2}{8a}t^2} \right)^2 \\
\end{split}
\]

Let us set our notation for the gaussian function of parameter $s>0$, 
$$\rho_s(v)=\exp(-\pi\frac{\|v\|^2 }{s^2} )\quad \forall v\in \mathbb R^n.$$
The continuous gaussian measure\footnote{We denoted the Lebsgue measure of dimension $d$ by $m_d$.} is 
$$\gamma_s(A) =  \int_A s^{-n}\rho_s(x)dm_d(x) ,$$
whereas the discrete gaussian on $\Lambda$ is the probability measure 
$$D_{\Lambda , s} = \rho_s(\Lambda )^{-1} \sum_{v\in \Lambda} \rho_s(v)\delta_v. $$
Recall the following corollary of a theorem of Banaszcyk theorem (lemma 1.5 in \cite{banaszczyk1993new}).

\begin{theorem}
Let $\Lambda$ an euclidean lattice of rank $d$ and $\xi \sim \mathcal D_{\Lambda , s}$,
$$\mathbb P(\|\xi - v\|> r ) \leq \exp(-\pi (\frac{r}{s} -\sqrt{\frac{d}{2\pi}})^2) \quad \forall r >\sqrt{\frac{n}{2\pi}}s $$
\end{theorem}

Let $W\subset \Lambda^\vee$ be a finite subset, and define 
$$f_W(t) = \frac{1}{|W|}\sum_{w\in W} \cos(2\pi \langle w , t \rangle) \quad \forall t \in \ell^2_n.$$
Let us denote by $L$ the positive number $2\pi\max_{w\in W} \|w\|_2$. Then
\[\begin{split}
|f_W(x) -f_W(y)| & \leq \frac{1}{|W|}\sum_{w\in W} |\cos(2\pi \langle w , x \rangle ) -\cos(2\pi \langle w , y \rangle) | \\
		 & \leq \frac{2\pi}{|W|}\sum_{w\in W} \|w\|_2 \|x-y\|_2\\
		 & \leq L\|x-y\|_2\\ 
\end{split}\]
i.e. $f_W$ is a $L$-Lipschitz function.  

If one uses a sieve to sample vectors from $W$, we can give the following bounds 
$$2\pi gh(\Lambda) \leq L \leq 2\pi\sqrt{\frac{4}{3}}gh(\Lambda) $$

\subsection{Analogy with codes}

For $\mathbb F_q$, where $q = p^\ell$, recall (see corollary 7.1.3 of \cite{scarabotti2018discrete}) that $\mathbb F_q$ and its dual are isomorphic as groups via the following isomorphism 
\[\left\{ \begin{array}{rcl}
\mathbb F_q 	& \rightarrow 	& \hat {\mathbb F_q} \\
x	& \mapsto 	& \left( y\mapsto \exp (\frac{2k\pi }{p}\text{Tr}_{\mathbb F_q / \mathbb F_p}(xy)) \right)\\
\end{array}\right.\]
The Fourier inversion formula also holds for every function $f : \mathbb F_q \rightarrow \mathbb C$ :
\[f(x) = \frac{1}{q} \sum_{\chi \in \hat{\mathbb F_q}} \hat f(\chi) \chi \]
For functions on $\mathbb F_q^n$ that are $C$-periodic, we are looking at the Fourier transform on the finite abelian group $\mathbb F_q / C$, whose dual is described by
\[ \chi_x(y) = \exp (\frac{2k\pi }{p}(x,y)_{\mathbb F_p} )\]
where $y \in C^\perp$, for 
\[C^{\perp} = \{y\in \mathbb F_q^n \ : \ (x,y)_{\mathbb F_p}= 0   \}.\]
and 
\[(x,y)_{\mathbb F_p} = \sum_{i=1}^n \text{Tr}_{\mathbb F_q / \mathbb F_p}(x_iy_i) \]
Several papers notice an analogy with dual attacks for linear codes. The latter are still abelian groups. Since they are finite, all functions are continuous. Moreover, $\text{CP}(\mathbb F_q^n / C)$ is the set of positive definite matrices indexed by $\mathbb F_q^n / C$. In this case the Fourier isomorphism of theorem \ref{BochnerLattices} takes the following form.

\begin{theorem}
For every $C$-periodic function $f : \mathbb F_q^n \rightarrow \mathbb C$ of positive type such that $f(0) = 1$, there exists a probability measure $\eta\in \text{Prob} (C^\vee)$ such that 
\[f(t) =\mathbb E[e^{\frac{2i\pi}{p} ( W , t)_{\mathbb F_p} } ]\quad\forall t\in \mathbb F_q^n ,\]
where $W$ is a random variable with law $\eta$.
\end{theorem}

Let us denote by $w(x)$ the Hamming weight of a vector $x\in\mathbb F^n_q$
\[w(x) = \sum_{i=1}^n 1_{(x_i\neq 0)}\]
and $d$ the corresponding distance.

\begin{lemma}
The Hamming distance is an invariant condionnally negative type kernel on $\mathbb F^n_q$.
\end{lemma}

\begin{proof}
The following function \[\Phi : \left\{ \begin{array}{rcl}
\mathbb F^n_q 	& \rightarrow 	& \mathbb R^{n\times q} \\
(x_i)_{i=1,n}	& \mapsto 	& [1_{(x_i = a )}]_{i=1,n , a\in\mathbb F_q}\\
\end{array}\right.\]
satisfies $\|\Phi(x)-\Phi(y)\|^2 = d(x,y) = w(x-y)$, hence the result.
\end{proof}
As a corollary, for every $t>0$ and $x\in C$, there exists a random variable $W$ with values in $C^{\perp}$ such that
\[\mathbb E[e^{\frac{2i\pi}{p} ( W , x)_{\mathbb F_p}}] = \Theta_{C}(t)^{-1}\sum_{c\in C} \exp(-tw(x-c))\]
with $\Theta_{C}(t) = \sum_{c\in C} \exp(-tw(c))$.

The summation Poisson formula takes the following form.
\begin{theorem}[Poisson formula for linear codes]
For every function $\varphi : \mathbb F_q^n \rightarrow \mathbb C$, the following equality 
\[\sum_{c\in C} \varphi(x-c) = \sum_{w\in C^\perp} \hat\varphi(w)e^{2i\pi \frac{\langle w , x\rangle }{q}}\quad\forall x\in \mathbb F_q^n\]
is satisfied.
\end{theorem}
We will use the notation 
\[\varphi (C - x) = \left( e^{-2i\pi \frac{\langle w , \bullet\rangle }{q}}\hat \varphi \right) (C^\perp) \]

\bibliographystyle{plain}
\bibliography{biblio}
\end{document}































